{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a113a176",
   "metadata": {},
   "source": [
    "# AI Job Market Data Cleaning \n",
    "This notebook performs comprehensive data cleaning on the AI job market dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acfb34c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries \n",
    "\n",
    "Import necessary Python libraries for data cleaning and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8504af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3b4d6",
   "metadata": {},
   "source": [
    "## 2. Load Dataset \n",
    "\n",
    "Load the AI job market dataset from CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775b3131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2000, 12)\n",
      "\n",
      "Column names: ['job_id', 'company_name', 'industry', 'job_title', 'skills_required', 'experience_level', 'employment_type', 'location', 'salary_range_usd', 'posted_date', 'company_size', 'tools_preferred']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_title</th>\n",
       "      <th>skills_required</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>location</th>\n",
       "      <th>salary_range_usd</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>company_size</th>\n",
       "      <th>tools_preferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Foster and Sons</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NumPy, Reinforcement Learning, PyTorch, Scikit...</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Tracybury, AR</td>\n",
       "      <td>92860-109598</td>\n",
       "      <td>2025/8/20</td>\n",
       "      <td>Large</td>\n",
       "      <td>KDB+, LangChain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Boyd, Myers and Ramirez</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Computer Vision Engineer</td>\n",
       "      <td>Scikit-learn, CUDA, SQL, Pandas</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Lake Scott, CU</td>\n",
       "      <td>78523-144875</td>\n",
       "      <td>2024/3/22</td>\n",
       "      <td>Large</td>\n",
       "      <td>FastAPI, KDB+, TensorFlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>King Inc</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Quant Researcher</td>\n",
       "      <td>MLflow, FastAPI, Azure, PyTorch, SQL, GCP</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>East Paige, CM</td>\n",
       "      <td>124496-217204</td>\n",
       "      <td>2025/9/18</td>\n",
       "      <td>Large</td>\n",
       "      <td>BigQuery, PyTorch, Scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cooper, Archer and Lynch</td>\n",
       "      <td>Tech</td>\n",
       "      <td>AI Product Manager</td>\n",
       "      <td>Scikit-learn, C++, Pandas, LangChain, AWS, R</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Perezview, FI</td>\n",
       "      <td>50908-123743</td>\n",
       "      <td>2024/5/8</td>\n",
       "      <td>Large</td>\n",
       "      <td>TensorFlow, BigQuery, MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hall LLC</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Excel, Keras, SQL, Hugging Face</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Contract</td>\n",
       "      <td>North Desireeland, NE</td>\n",
       "      <td>98694-135413</td>\n",
       "      <td>2025/2/24</td>\n",
       "      <td>Large</td>\n",
       "      <td>PyTorch, LangChain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id              company_name    industry                 job_title  \\\n",
       "0       1           Foster and Sons  Healthcare              Data Analyst   \n",
       "1       2   Boyd, Myers and Ramirez        Tech  Computer Vision Engineer   \n",
       "2       3                  King Inc        Tech          Quant Researcher   \n",
       "3       4  Cooper, Archer and Lynch        Tech        AI Product Manager   \n",
       "4       5                  Hall LLC     Finance            Data Scientist   \n",
       "\n",
       "                                     skills_required experience_level  \\\n",
       "0  NumPy, Reinforcement Learning, PyTorch, Scikit...              Mid   \n",
       "1                    Scikit-learn, CUDA, SQL, Pandas           Senior   \n",
       "2          MLflow, FastAPI, Azure, PyTorch, SQL, GCP            Entry   \n",
       "3       Scikit-learn, C++, Pandas, LangChain, AWS, R              Mid   \n",
       "4                    Excel, Keras, SQL, Hugging Face           Senior   \n",
       "\n",
       "  employment_type               location salary_range_usd posted_date  \\\n",
       "0       Full-time          Tracybury, AR     92860-109598   2025/8/20   \n",
       "1       Full-time         Lake Scott, CU     78523-144875   2024/3/22   \n",
       "2       Full-time         East Paige, CM    124496-217204   2025/9/18   \n",
       "3       Full-time          Perezview, FI     50908-123743    2024/5/8   \n",
       "4        Contract  North Desireeland, NE     98694-135413   2025/2/24   \n",
       "\n",
       "  company_size                  tools_preferred  \n",
       "0        Large                  KDB+, LangChain  \n",
       "1        Large        FastAPI, KDB+, TensorFlow  \n",
       "2        Large  BigQuery, PyTorch, Scikit-learn  \n",
       "3        Large     TensorFlow, BigQuery, MLflow  \n",
       "4        Large               PyTorch, LangChain  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../dataset/ai_job_market.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103f4ce",
   "metadata": {},
   "source": [
    "## 3. Check Missing Values \n",
    "\n",
    "Identify and analyze missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1cbf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Analysis:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Count, Percentage]\n",
      "Index: []\n",
      "\n",
      "Total missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(missing_data[missing_data['Missing Count'] > 0])\n",
    "print(f\"\\nTotal missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be7db1",
   "metadata": {},
   "source": [
    "## 4. Handle Missing Values\n",
    "\n",
    "Handle missing values using appropriate strategies for different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f101cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after handling missing values: 2000\n",
      "Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Handle missing values in text columns with 'Unknown'\n",
    "text_columns = ['company_name', 'industry', 'job_title', 'skills_required', \n",
    "                'tools_preferred', 'location']\n",
    "for col in text_columns:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Handle missing values in categorical columns with mode\n",
    "categorical_columns = ['experience_level', 'employment_type', 'company_size']\n",
    "for col in categorical_columns:\n",
    "    if col in df_cleaned.columns:\n",
    "        mode_value = df_cleaned[col].mode()[0] if not df_cleaned[col].mode().empty else 'Unknown'\n",
    "        df_cleaned[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Drop rows with missing salary information (critical for analysis)\n",
    "if 'salary_range_usd' in df_cleaned.columns:\n",
    "    df_cleaned = df_cleaned.dropna(subset=['salary_range_usd'])\n",
    "\n",
    "print(f\"Rows after handling missing values: {len(df_cleaned)}\")\n",
    "print(f\"Remaining missing values: {df_cleaned.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a012118",
   "metadata": {},
   "source": [
    "## 5. Standardize Job Titles\n",
    "\n",
    "Standardize job titles by converting to lowercase and removing extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a1e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Title Distribution:\n",
      "job_category\n",
      "Data Analyst                271\n",
      "NLP Engineer                265\n",
      "AI Product Manager          258\n",
      "Quant Researcher            251\n",
      "ML Engineer                 250\n",
      "Data Scientist              238\n",
      "AI Researcher               237\n",
      "Computer Vision Engineer    230\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize job titles\n",
    "df_cleaned['job_title_standardized'] = df_cleaned['job_title'].str.strip().str.title()\n",
    "\n",
    "# Create job title categories\n",
    "def categorize_job_title(title):\n",
    "    title_lower = str(title).lower()\n",
    "    if 'data scientist' in title_lower or 'data science' in title_lower:\n",
    "        return 'Data Scientist'\n",
    "    elif 'data analyst' in title_lower:\n",
    "        return 'Data Analyst'\n",
    "    elif 'ml engineer' in title_lower or 'machine learning' in title_lower:\n",
    "        return 'ML Engineer'\n",
    "    elif 'nlp' in title_lower:\n",
    "        return 'NLP Engineer'\n",
    "    elif 'computer vision' in title_lower or 'cv engineer' in title_lower:\n",
    "        return 'Computer Vision Engineer'\n",
    "    elif 'ai researcher' in title_lower or 'research scientist' in title_lower:\n",
    "        return 'AI Researcher'\n",
    "    elif 'ai product manager' in title_lower or 'product manager' in title_lower:\n",
    "        return 'AI Product Manager'\n",
    "    elif 'quant' in title_lower:\n",
    "        return 'Quant Researcher'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df_cleaned['job_category'] = df_cleaned['job_title'].apply(categorize_job_title)\n",
    "\n",
    "print(\"Job Title Distribution:\")\n",
    "print(df_cleaned['job_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bbd71",
   "metadata": {},
   "source": [
    "## 6. Standardize Skills\n",
    "\n",
    "Extract and standardize skills from the skills_required and tools_preferred columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7e055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of skills required: 4.49\n",
      "Average number of tools preferred: 1.98\n"
     ]
    }
   ],
   "source": [
    "# Function to clean and standardize skills\n",
    "def clean_skills(skill_string):\n",
    "    if pd.isna(skill_string) or skill_string == 'Unknown':\n",
    "        return []\n",
    "    # Remove quotes and split by comma\n",
    "    skills = [skill.strip() for skill in str(skill_string).split(',')]\n",
    "    # Standardize common variations\n",
    "    skill_map = {\n",
    "        'python': 'Python',\n",
    "        'r': 'R',\n",
    "        'sql': 'SQL',\n",
    "        'pytorch': 'PyTorch',\n",
    "        'tensorflow': 'TensorFlow',\n",
    "        'keras': 'Keras',\n",
    "        'scikit-learn': 'Scikit-learn',\n",
    "        'pandas': 'Pandas',\n",
    "        'numpy': 'NumPy',\n",
    "        'excel': 'Excel',\n",
    "        'aws': 'AWS',\n",
    "        'azure': 'Azure',\n",
    "        'gcp': 'GCP',\n",
    "        'cuda': 'CUDA',\n",
    "        'c++': 'C++',\n",
    "        'flask': 'Flask',\n",
    "        'fastapi': 'FastAPI',\n",
    "        'mlflow': 'MLflow',\n",
    "        'langchain': 'LangChain',\n",
    "        'hugging face': 'Hugging Face',\n",
    "        'power bi': 'Power BI',\n",
    "        'reinforcement learning': 'Reinforcement Learning'\n",
    "    }\n",
    "    \n",
    "    standardized_skills = []\n",
    "    for skill in skills:\n",
    "        skill_lower = skill.lower().strip()\n",
    "        standardized_skills.append(skill_map.get(skill_lower, skill.strip()))\n",
    "    \n",
    "    return standardized_skills\n",
    "\n",
    "# Apply standardization\n",
    "df_cleaned['skills_list'] = df_cleaned['skills_required'].apply(clean_skills)\n",
    "df_cleaned['tools_list'] = df_cleaned['tools_preferred'].apply(clean_skills)\n",
    "\n",
    "# Count number of skills\n",
    "df_cleaned['num_skills_required'] = df_cleaned['skills_list'].apply(len)\n",
    "df_cleaned['num_tools_preferred'] = df_cleaned['tools_list'].apply(len)\n",
    "\n",
    "print(f\"Average number of skills required: {df_cleaned['num_skills_required'].mean():.2f}\")\n",
    "print(f\"Average number of tools preferred: {df_cleaned['num_tools_preferred'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3516bd7e",
   "metadata": {},
   "source": [
    "## 7. Calculate Average Salary\n",
    "\n",
    "Parse salary range and calculate average salary for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c98fee8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary Statistics:\n",
      "Average Salary: $123,040.00\n",
      "Median Salary: $123,202.75\n",
      "Min Salary: $47,578.50\n",
      "Max Salary: $197,776.50\n",
      "\n",
      "Salary Distribution:\n",
      "salary_category\n",
      "High (100K-150K)     900\n",
      "Very High (>150K)    521\n",
      "Mid (70K-100K)       448\n",
      "Low (<70K)           131\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to parse salary range and calculate average\n",
    "def parse_salary(salary_string):\n",
    "    if pd.isna(salary_string):\n",
    "        return None, None, None\n",
    "    \n",
    "    # Extract numbers from salary range (format: \"min-max\")\n",
    "    match = re.findall(r'(\\d+)', str(salary_string))\n",
    "    \n",
    "    if len(match) >= 2:\n",
    "        min_salary = int(match[0])\n",
    "        max_salary = int(match[1])\n",
    "        avg_salary = (min_salary + max_salary) / 2\n",
    "        return min_salary, max_salary, avg_salary\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "# Apply salary parsing\n",
    "salary_data = df_cleaned['salary_range_usd'].apply(parse_salary)\n",
    "df_cleaned['salary_min'] = salary_data.apply(lambda x: x[0])\n",
    "df_cleaned['salary_max'] = salary_data.apply(lambda x: x[1])\n",
    "df_cleaned['salary_avg'] = salary_data.apply(lambda x: x[2])\n",
    "\n",
    "# Create salary categories\n",
    "def categorize_salary(avg_salary):\n",
    "    if pd.isna(avg_salary):\n",
    "        return 'Unknown'\n",
    "    elif avg_salary < 70000:\n",
    "        return 'Low (<70K)'\n",
    "    elif avg_salary < 100000:\n",
    "        return 'Mid (70K-100K)'\n",
    "    elif avg_salary < 150000:\n",
    "        return 'High (100K-150K)'\n",
    "    else:\n",
    "        return 'Very High (>150K)'\n",
    "\n",
    "df_cleaned['salary_category'] = df_cleaned['salary_avg'].apply(categorize_salary)\n",
    "\n",
    "print(\"Salary Statistics:\")\n",
    "print(f\"Average Salary: ${df_cleaned['salary_avg'].mean():,.2f}\")\n",
    "print(f\"Median Salary: ${df_cleaned['salary_avg'].median():,.2f}\")\n",
    "print(f\"Min Salary: ${df_cleaned['salary_avg'].min():,.2f}\")\n",
    "print(f\"Max Salary: ${df_cleaned['salary_avg'].max():,.2f}\")\n",
    "print(f\"\\nSalary Distribution:\")\n",
    "print(df_cleaned['salary_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75609257",
   "metadata": {},
   "source": [
    "## 8. Standardize Location Data\n",
    "\n",
    "Parse and standardize location information into city, state/country codes, and regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d39cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Distribution:\n",
      "region\n",
      "Other              591\n",
      "Africa             336\n",
      "Europe             332\n",
      "Asia               280\n",
      "Caribbean          136\n",
      "Oceania            115\n",
      "South America       84\n",
      "Central America     62\n",
      "North America       32\n",
      "Middle East         32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique cities: 1858\n",
      "Total unique countries: 134\n",
      "\n",
      "Sample countries:\n",
      "country\n",
      "Unknown              591\n",
      "Papua New Guinea      19\n",
      "Bhutan                18\n",
      "Fiji                  18\n",
      "Croatia               18\n",
      "Barbados              18\n",
      "Iraq                  17\n",
      "Uzbekistan            16\n",
      "Jamaica               16\n",
      "Equatorial Guinea     16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to parse location\n",
    "def parse_location(location_string):\n",
    "    if pd.isna(location_string) or location_string == 'Unknown':\n",
    "        return None, None\n",
    "    \n",
    "    # Split by comma to get city and country code\n",
    "    parts = str(location_string).split(',')\n",
    "    if len(parts) >= 2:\n",
    "        city = parts[0].strip()\n",
    "        country_code = parts[1].strip()\n",
    "        return city, country_code\n",
    "    else:\n",
    "        return location_string, None\n",
    "\n",
    "# Apply location parsing\n",
    "location_data = df_cleaned['location'].apply(parse_location)\n",
    "df_cleaned['city'] = location_data.apply(lambda x: x[0])\n",
    "df_cleaned['country_code'] = location_data.apply(lambda x: x[1])\n",
    "\n",
    "# Map country codes to country names (ISO 3166-1 alpha-2)\n",
    "country_code_to_name = {\n",
    "    # North America\n",
    "    'US': 'United States', 'CA': 'Canada', 'MX': 'Mexico',\n",
    "    \n",
    "    # Europe\n",
    "    'GB': 'United Kingdom', 'DE': 'Germany', 'FR': 'France', 'IT': 'Italy',\n",
    "    'ES': 'Spain', 'NL': 'Netherlands', 'SE': 'Sweden', 'NO': 'Norway',\n",
    "    'PL': 'Poland', 'TR': 'Turkey', 'PT': 'Portugal', 'BE': 'Belgium',\n",
    "    'RO': 'Romania', 'BG': 'Bulgaria', 'CZ': 'Czech Republic', 'HU': 'Hungary',\n",
    "    'LT': 'Lithuania', 'LV': 'Latvia', 'LU': 'Luxembourg', 'AD': 'Andorra',\n",
    "    'AG': 'Antigua and Barbuda', 'LR': 'Liberia', 'LC': 'Saint Lucia', \n",
    "    'BB': 'Barbados', 'BT': 'Bhutan', 'HR': 'Croatia', 'ME': 'Montenegro',\n",
    "    'MC': 'Monaco', 'RS': 'Serbia', 'SC': 'Seychelles', 'AM': 'Armenia',\n",
    "    'UA': 'Ukraine', 'KZ': 'Kazakhstan', 'GE': 'Georgia', 'FI': 'Finland',\n",
    "    'BR': 'Brazil', 'AR': 'Argentina', 'NE': 'Niger', 'ID': 'Indonesia',\n",
    "    'MA': 'Morocco', 'AZ': 'Azerbaijan',\n",
    "    \n",
    "    # Asia\n",
    "    'CN': 'China', 'JP': 'Japan', 'IN': 'India', 'KR': 'South Korea',\n",
    "    'SG': 'Singapore', 'TH': 'Thailand', 'MY': 'Malaysia', 'VN': 'Vietnam',\n",
    "    'PH': 'Philippines', 'TW': 'Taiwan', 'HK': 'Hong Kong', 'PK': 'Pakistan',\n",
    "    'BD': 'Bangladesh', 'IQ': 'Iraq', 'KH': 'Cambodia', 'MM': 'Myanmar',\n",
    "    'KG': 'Kyrgyzstan', 'YE': 'Yemen', 'UZ': 'Uzbekistan', 'KW': 'Kuwait',\n",
    "    'IR': 'Iran', 'KE': 'Kenya', 'NG': 'Nigeria',\n",
    "    \n",
    "    # Oceania\n",
    "    'AU': 'Australia', 'NZ': 'New Zealand', 'FJ': 'Fiji', 'PG': 'Papua New Guinea',\n",
    "    'KI': 'Kiribati', 'PW': 'Palau',\n",
    "    \n",
    "    # South America\n",
    "    'CL': 'Chile', 'CO': 'Colombia', 'PE': 'Peru', 'VE': 'Venezuela',\n",
    "    'UY': 'Uruguay', 'PY': 'Paraguay', 'GY': 'Guyana',\n",
    "    \n",
    "    # Africa\n",
    "    'ZA': 'South Africa', 'EG': 'Egypt', 'ET': 'Ethiopia', 'GH': 'Ghana',\n",
    "    'TZ': 'Tanzania', 'UG': 'Uganda', 'TD': 'Chad', 'GQ': 'Equatorial Guinea',\n",
    "    'BF': 'Burkina Faso', 'SN': 'Senegal', 'TG': 'Togo', 'CI': \"Côte d'Ivoire\",\n",
    "    'GW': 'Guinea-Bissau', 'BW': 'Botswana', 'LS': 'Lesotho', 'BS': 'Bahamas',\n",
    "    'DO': 'Dominican Republic', 'MR': 'Mauritania', 'DZ': 'Algeria',\n",
    "    'CF': 'Central African Republic', 'AO': 'Angola', 'SA': 'Saudi Arabia',\n",
    "    \n",
    "    # Central America / Caribbean\n",
    "    'GT': 'Guatemala', 'HN': 'Honduras', 'SV': 'El Salvador', 'CR': 'Costa Rica',\n",
    "    'PA': 'Panama', 'BZ': 'Belize', 'JM': 'Jamaica', 'TT': 'Trinidad and Tobago',\n",
    "    'BN': 'Brunei', 'KN': 'Saint Kitts and Nevis', 'KM': 'Comoros',\n",
    "    'SB': 'Solomon Islands', 'VC': 'Saint Vincent and the Grenadines',\n",
    "    'QA': 'Qatar',\n",
    "    \n",
    "    # Other regions\n",
    "    'RU': 'Russia', 'CU': 'Cuba', 'CM': 'Cameroon', 'BA': 'Bosnia and Herzegovina',\n",
    "    'FM': 'Micronesia', 'LI': 'Liechtenstein', 'VU': 'Vanuatu',\n",
    "    'PS': 'Palestine', 'MD': 'Moldova', 'ZW': 'Zimbabwe', 'MK': 'North Macedonia',\n",
    "    'DM': 'Dominica', 'MG': 'Madagascar', 'MW': 'Malawi', 'BJ': 'Benin',\n",
    "    'TL': 'Timor-Leste', 'BI': 'Burundi', 'SL': 'Sierra Leone'\n",
    "}\n",
    "\n",
    "# Map country codes to regions\n",
    "country_to_region = {\n",
    "    # North America\n",
    "    'US': 'North America', 'CA': 'North America', 'MX': 'North America',\n",
    "    'AR': 'South America', 'NE': 'Africa', 'ID': 'Asia',\n",
    "    'MA': 'Africa', 'AZ': 'Asia',\n",
    "    \n",
    "    # Europe\n",
    "    'GB': 'Europe', 'DE': 'Europe', 'FR': 'Europe', 'IT': 'Europe', \n",
    "    'ES': 'Europe', 'NL': 'Europe', 'SE': 'Europe', 'NO': 'Europe',\n",
    "    'PL': 'Europe', 'TR': 'Europe', 'PT': 'Europe', 'BE': 'Europe',\n",
    "    'RO': 'Europe', 'BG': 'Europe', 'CZ': 'Europe', 'HU': 'Europe',\n",
    "    'LT': 'Europe', 'LV': 'Europe', 'LU': 'Europe', 'AD': 'Europe',\n",
    "    'AG': 'Caribbean', 'LR': 'Africa', 'LC': 'Caribbean', 'BB': 'Caribbean',\n",
    "    'BT': 'Asia', 'HR': 'Europe', 'ME': 'Europe', 'MC': 'Europe',\n",
    "    'RS': 'Europe', 'SC': 'Africa', 'AM': 'Asia', 'UA': 'Europe',\n",
    "    'KZ': 'Asia', 'GE': 'Asia', 'FI': 'Europe', 'BR': 'South America',\n",
    "    \n",
    "    # Asia\n",
    "    'CN': 'Asia', 'JP': 'Asia', 'IN': 'Asia', 'KR': 'Asia', 'SG': 'Asia',\n",
    "    'TH': 'Asia', 'MY': 'Asia', 'VN': 'Asia', 'PH': 'Asia', 'TW': 'Asia',\n",
    "    'HK': 'Asia', 'PK': 'Asia', 'BD': 'Asia', 'IQ': 'Asia', 'KH': 'Asia',\n",
    "    'MM': 'Asia', 'KG': 'Asia', 'YE': 'Asia', 'UZ': 'Asia', 'KW': 'Asia',\n",
    "    'IR': 'Asia', 'KE': 'Africa', 'NG': 'Africa',\n",
    "    \n",
    "    # Oceania\n",
    "    'AU': 'Oceania', 'NZ': 'Oceania', 'FJ': 'Oceania', 'PG': 'Oceania',\n",
    "    'KI': 'Oceania', 'PW': 'Oceania',\n",
    "    \n",
    "    # South America\n",
    "    'CL': 'South America', 'CO': 'South America',\n",
    "    'PE': 'South America', 'VE': 'South America', 'UY': 'South America',\n",
    "    'PY': 'South America', 'GY': 'South America',\n",
    "    \n",
    "    # Africa\n",
    "    'ZA': 'Africa', 'EG': 'Africa', 'ET': 'Africa', 'GH': 'Africa',\n",
    "    'TZ': 'Africa', 'UG': 'Africa', 'TD': 'Africa', 'GQ': 'Africa',\n",
    "    'BF': 'Africa', 'SN': 'Africa', 'TG': 'Africa', 'CI': 'Africa',\n",
    "    'GW': 'Africa', 'BW': 'Africa', 'LS': 'Africa', 'BS': 'Caribbean',\n",
    "    'DO': 'Caribbean', 'MR': 'Africa', 'DZ': 'Africa',\n",
    "    'CF': 'Africa', 'AO': 'Africa', 'SA': 'Middle East',\n",
    "    \n",
    "    # Central America / Caribbean\n",
    "    'GT': 'Central America', 'HN': 'Central America', 'SV': 'Central America',\n",
    "    'CR': 'Central America', 'PA': 'Central America', 'BZ': 'Central America',\n",
    "    'JM': 'Caribbean', 'TT': 'Caribbean', 'BN': 'Asia', 'KN': 'Caribbean',\n",
    "    'KM': 'Africa', 'SB': 'Oceania', 'VC': 'Caribbean', 'QA': 'Middle East',\n",
    "    \n",
    "    # Other regions\n",
    "    'RU': 'Europe', 'CU': 'Caribbean', 'CM': 'Africa', 'BA': 'Europe',\n",
    "    'FM': 'Oceania', 'LI': 'Europe', 'VU': 'Oceania',\n",
    "    'PS': 'Middle East', 'MD': 'Europe', 'ZW': 'Africa', 'MK': 'Europe',\n",
    "    'DM': 'Caribbean', 'MG': 'Africa', 'MW': 'Africa', 'BJ': 'Africa',\n",
    "    'TL': 'Asia', 'BI': 'Africa', 'SL': 'Africa'\n",
    "}\n",
    "\n",
    "# Map country codes to country names and regions\n",
    "df_cleaned['country'] = df_cleaned['country_code'].map(country_code_to_name)\n",
    "df_cleaned['country'].fillna('Unknown', inplace=True)\n",
    "\n",
    "df_cleaned['region'] = df_cleaned['country_code'].map(country_to_region)\n",
    "df_cleaned['region'].fillna('Other', inplace=True)\n",
    "\n",
    "print(\"Region Distribution:\")\n",
    "print(df_cleaned['region'].value_counts())\n",
    "print(f\"\\nTotal unique cities: {df_cleaned['city'].nunique()}\")\n",
    "print(f\"Total unique countries: {df_cleaned['country'].nunique()}\")\n",
    "print(f\"\\nSample countries:\")\n",
    "print(df_cleaned['country'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c4387",
   "metadata": {},
   "source": [
    "## 9. Standardize and Categorize Industries\n",
    "\n",
    "Standardize industry names and group them into broader categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d540a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Industries:\n",
      "industry_standardized\n",
      "Automotive    300\n",
      "Education     294\n",
      "Retail        293\n",
      "E-Commerce    291\n",
      "Finance       279\n",
      "Tech          274\n",
      "Healthcare    269\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "\n",
      "Industry Categories:\n",
      "industry_category\n",
      "Retail & E-commerce            584\n",
      "Automotive & Transportation    300\n",
      "Education                      294\n",
      "Finance & Banking              279\n",
      "Technology                     274\n",
      "Healthcare                     269\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize industry names\n",
    "df_cleaned['industry_standardized'] = df_cleaned['industry'].str.strip().str.title()\n",
    "\n",
    "# Function to categorize industries into broader groups\n",
    "def categorize_industry(industry):\n",
    "    if pd.isna(industry) or industry == 'Unknown':\n",
    "        return 'Other'\n",
    "    \n",
    "    industry_lower = str(industry).lower()\n",
    "    \n",
    "    # Finance related\n",
    "    if any(keyword in industry_lower for keyword in ['finance', 'banking', 'investment', 'insurance', 'fintech']):\n",
    "        return 'Finance & Banking'\n",
    "    \n",
    "    # Technology\n",
    "    elif any(keyword in industry_lower for keyword in ['tech', 'technology', 'software', 'it', 'computer']):\n",
    "        return 'Technology'\n",
    "    \n",
    "    # Healthcare\n",
    "    elif any(keyword in industry_lower for keyword in ['health', 'healthcare', 'medical', 'pharma', 'hospital', 'biotech']):\n",
    "        return 'Healthcare'\n",
    "    \n",
    "    # Retail & E-commerce\n",
    "    elif any(keyword in industry_lower for keyword in ['retail', 'e-commerce', 'ecommerce', 'shopping', 'commerce']):\n",
    "        return 'Retail & E-commerce'\n",
    "    \n",
    "    # Education\n",
    "    elif any(keyword in industry_lower for keyword in ['education', 'university', 'school', 'learning', 'edtech']):\n",
    "        return 'Education'\n",
    "    \n",
    "    # Automotive & Transportation\n",
    "    elif any(keyword in industry_lower for keyword in ['automotive', 'automobile', 'transport', 'vehicle', 'car']):\n",
    "        return 'Automotive & Transportation'\n",
    "    \n",
    "    # Manufacturing\n",
    "    elif any(keyword in industry_lower for keyword in ['manufacturing', 'industrial', 'production']):\n",
    "        return 'Manufacturing'\n",
    "    \n",
    "    # Media & Entertainment\n",
    "    elif any(keyword in industry_lower for keyword in ['media', 'entertainment', 'gaming', 'streaming']):\n",
    "        return 'Media & Entertainment'\n",
    "    \n",
    "    # Energy & Utilities\n",
    "    elif any(keyword in industry_lower for keyword in ['energy', 'utility', 'utilities', 'power', 'oil', 'gas']):\n",
    "        return 'Energy & Utilities'\n",
    "    \n",
    "    # Telecommunications\n",
    "    elif any(keyword in industry_lower for keyword in ['telecom', 'telecommunications', 'communication']):\n",
    "        return 'Telecommunications'\n",
    "    \n",
    "    # Consulting\n",
    "    elif any(keyword in industry_lower for keyword in ['consulting', 'advisory', 'professional services']):\n",
    "        return 'Consulting'\n",
    "    \n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df_cleaned['industry_category'] = df_cleaned['industry'].apply(categorize_industry)\n",
    "\n",
    "print(\"Original Industries:\")\n",
    "print(df_cleaned['industry_standardized'].value_counts())\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"Industry Categories:\")\n",
    "print(df_cleaned['industry_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a5959",
   "metadata": {},
   "source": [
    "## 10. Standardize Experience Level and Employment Type\n",
    "\n",
    "Standardize experience level and employment type for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f54cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience Level Distribution:\n",
      "experience_level_standardized\n",
      "Entry     702\n",
      "Mid       668\n",
      "Senior    630\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "\n",
      "Employment Type Distribution:\n",
      "employment_type_standardized\n",
      "Internship    574\n",
      "Full-Time     509\n",
      "Contract      465\n",
      "Remote        452\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize experience level\n",
    "experience_mapping = {\n",
    "    'entry': 'Entry',\n",
    "    'junior': 'Entry',\n",
    "    'mid': 'Mid',\n",
    "    'intermediate': 'Mid',\n",
    "    'senior': 'Senior',\n",
    "    'lead': 'Senior',\n",
    "    'principal': 'Senior',\n",
    "    'expert': 'Senior'\n",
    "}\n",
    "\n",
    "df_cleaned['experience_level_standardized'] = df_cleaned['experience_level'].str.lower().map(\n",
    "    experience_mapping\n",
    ").fillna(df_cleaned['experience_level'])\n",
    "\n",
    "# Standardize employment type\n",
    "employment_mapping = {\n",
    "    'full-time': 'Full-Time',\n",
    "    'fulltime': 'Full-Time',\n",
    "    'full time': 'Full-Time',\n",
    "    'part-time': 'Part-Time',\n",
    "    'parttime': 'Part-Time',\n",
    "    'part time': 'Part-Time',\n",
    "    'contract': 'Contract',\n",
    "    'contractor': 'Contract',\n",
    "    'freelance': 'Contract',\n",
    "    'internship': 'Internship',\n",
    "    'intern': 'Internship',\n",
    "    'remote': 'Remote',\n",
    "    'temporary': 'Temporary',\n",
    "    'temp': 'Temporary'\n",
    "}\n",
    "\n",
    "df_cleaned['employment_type_standardized'] = df_cleaned['employment_type'].str.lower().map(\n",
    "    employment_mapping\n",
    ").fillna(df_cleaned['employment_type'])\n",
    "\n",
    "print(\"Experience Level Distribution:\")\n",
    "print(df_cleaned['experience_level_standardized'].value_counts())\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"Employment Type Distribution:\")\n",
    "print(df_cleaned['employment_type_standardized'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372987d",
   "metadata": {},
   "source": [
    "## 11. Standardize Company Size\n",
    "\n",
    "Standardize company size categories for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58a7ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Size Distribution:\n",
      "company_size_standardized\n",
      "Startup    672\n",
      "Mid        671\n",
      "Large      657\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize company size\n",
    "company_size_mapping = {\n",
    "    'startup': 'Startup',\n",
    "    'small': 'Small',\n",
    "    'mid': 'Mid',\n",
    "    'medium': 'Mid',\n",
    "    'mid-size': 'Mid',\n",
    "    'large': 'Large',\n",
    "    'enterprise': 'Large'\n",
    "}\n",
    "\n",
    "df_cleaned['company_size_standardized'] = df_cleaned['company_size'].str.lower().map(\n",
    "    company_size_mapping\n",
    ").fillna(df_cleaned['company_size'])\n",
    "\n",
    "print(\"Company Size Distribution:\")\n",
    "print(df_cleaned['company_size_standardized'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106564b1",
   "metadata": {},
   "source": [
    "## 12. Parse and Standardize Posted Date\n",
    "\n",
    "Convert posted date to datetime format and extract useful time features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f0ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range:\n",
      "Earliest posting: 2023-09-21 00:00:00\n",
      "Latest posting: 2025-09-19 00:00:00\n",
      "\n",
      "Postings by Year:\n",
      "posted_year\n",
      "2023     271\n",
      "2024    1006\n",
      "2025     723\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Postings by Quarter:\n",
      "posted_quarter\n",
      "1    529\n",
      "2    447\n",
      "3    521\n",
      "4    503\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert posted_date to datetime\n",
    "df_cleaned['posted_date_parsed'] = pd.to_datetime(df_cleaned['posted_date'], format='%Y/%m/%d', errors='coerce')\n",
    "\n",
    "# Extract time-based features\n",
    "df_cleaned['posted_year'] = df_cleaned['posted_date_parsed'].dt.year\n",
    "df_cleaned['posted_month'] = df_cleaned['posted_date_parsed'].dt.month\n",
    "df_cleaned['posted_quarter'] = df_cleaned['posted_date_parsed'].dt.quarter\n",
    "df_cleaned['posted_month_name'] = df_cleaned['posted_date_parsed'].dt.strftime('%B')\n",
    "\n",
    "print(\"Date Range:\")\n",
    "print(f\"Earliest posting: {df_cleaned['posted_date_parsed'].min()}\")\n",
    "print(f\"Latest posting: {df_cleaned['posted_date_parsed'].max()}\")\n",
    "print(f\"\\nPostings by Year:\")\n",
    "print(df_cleaned['posted_year'].value_counts().sort_index())\n",
    "print(f\"\\nPostings by Quarter:\")\n",
    "print(df_cleaned['posted_quarter'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3f52c",
   "metadata": {},
   "source": [
    "## 13. Data Quality Summary\n",
    "\n",
    "Summarize data quality after cleaning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a977ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA CLEANING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "1. Dataset Size:\n",
      "   Original rows: 2000\n",
      "   Cleaned rows: 2000\n",
      "   Rows removed: 0\n",
      "\n",
      "2. Missing Values:\n",
      "   Total missing values: 0\n",
      "\n",
      "3. New Features Created:\n",
      "   Total new features: 24\n",
      "   Feature names: job_title_standardized, job_category, skills_list, tools_list, num_skills_required, num_tools_preferred, salary_min, salary_max, salary_avg, salary_category...\n",
      "\n",
      "4. Data Standardization:\n",
      "   ✓ Job titles standardized and categorized\n",
      "   ✓ Skills and tools parsed and standardized\n",
      "   ✓ Salary ranges converted to average values\n",
      "   ✓ Locations parsed into city, country code, country name, and region\n",
      "   ✓ Industries categorized into broader groups\n",
      "   ✓ Experience levels standardized\n",
      "   ✓ Employment types standardized\n",
      "   ✓ Company sizes standardized\n",
      "   ✓ Dates parsed and time features extracted\n",
      "\n",
      "5. Data Types:\n",
      "job_id                                    int64\n",
      "company_name                             object\n",
      "industry                                 object\n",
      "job_title                                object\n",
      "skills_required                          object\n",
      "experience_level                         object\n",
      "employment_type                          object\n",
      "location                                 object\n",
      "salary_range_usd                         object\n",
      "posted_date                              object\n",
      "company_size                             object\n",
      "tools_preferred                          object\n",
      "job_title_standardized                   object\n",
      "job_category                             object\n",
      "skills_list                              object\n",
      "tools_list                               object\n",
      "num_skills_required                       int64\n",
      "num_tools_preferred                       int64\n",
      "salary_min                                int64\n",
      "salary_max                                int64\n",
      "salary_avg                              float64\n",
      "salary_category                          object\n",
      "city                                     object\n",
      "country_code                             object\n",
      "country                                  object\n",
      "region                                   object\n",
      "industry_standardized                    object\n",
      "industry_category                        object\n",
      "experience_level_standardized            object\n",
      "employment_type_standardized             object\n",
      "company_size_standardized                object\n",
      "posted_date_parsed               datetime64[ns]\n",
      "posted_year                               int32\n",
      "posted_month                              int32\n",
      "posted_quarter                            int32\n",
      "posted_month_name                        object\n",
      "dtype: object\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Data quality summary\n",
    "print(\"=\"*70)\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. Dataset Size:\")\n",
    "print(f\"   Original rows: {len(df)}\")\n",
    "print(f\"   Cleaned rows: {len(df_cleaned)}\")\n",
    "print(f\"   Rows removed: {len(df) - len(df_cleaned)}\")\n",
    "\n",
    "print(f\"\\n2. Missing Values:\")\n",
    "print(f\"   Total missing values: {df_cleaned.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\n3. New Features Created:\")\n",
    "new_features = [\n",
    "    'job_title_standardized', 'job_category', 'skills_list', 'tools_list',\n",
    "    'num_skills_required', 'num_tools_preferred', 'salary_min', 'salary_max',\n",
    "    'salary_avg', 'salary_category', 'city', 'country_code', 'country', 'region',\n",
    "    'industry_standardized', 'industry_category', 'experience_level_standardized',\n",
    "    'employment_type_standardized', 'company_size_standardized', 'posted_date_parsed',\n",
    "    'posted_year', 'posted_month', 'posted_quarter', 'posted_month_name'\n",
    "]\n",
    "print(f\"   Total new features: {len(new_features)}\")\n",
    "print(f\"   Feature names: {', '.join(new_features[:10])}...\")\n",
    "\n",
    "print(f\"\\n4. Data Standardization:\")\n",
    "print(f\"   ✓ Job titles standardized and categorized\")\n",
    "print(f\"   ✓ Skills and tools parsed and standardized\")\n",
    "print(f\"   ✓ Salary ranges converted to average values\")\n",
    "print(f\"   ✓ Locations parsed into city, country code, country name, and region\")\n",
    "print(f\"   ✓ Industries categorized into broader groups\")\n",
    "print(f\"   ✓ Experience levels standardized\")\n",
    "print(f\"   ✓ Employment types standardized\")\n",
    "print(f\"   ✓ Company sizes standardized\")\n",
    "print(f\"   ✓ Dates parsed and time features extracted\")\n",
    "\n",
    "print(f\"\\n5. Data Types:\")\n",
    "print(df_cleaned.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5354d9b",
   "metadata": {},
   "source": [
    "## 14. View Sample of Cleaned Data\n",
    "\n",
    "Display a sample of the cleaned dataset with key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb11f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Cleaned Data (Key Features):\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_category</th>\n",
       "      <th>industry_category</th>\n",
       "      <th>experience_level_standardized</th>\n",
       "      <th>employment_type_standardized</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>num_skills_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Foster and Sons</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>101229.0</td>\n",
       "      <td>Tracybury</td>\n",
       "      <td>South America</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Boyd, Myers and Ramirez</td>\n",
       "      <td>Computer Vision Engineer</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>111699.0</td>\n",
       "      <td>Lake Scott</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>King Inc</td>\n",
       "      <td>Quant Researcher</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>170850.0</td>\n",
       "      <td>East Paige</td>\n",
       "      <td>Africa</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cooper, Archer and Lynch</td>\n",
       "      <td>AI Product Manager</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>87325.5</td>\n",
       "      <td>Perezview</td>\n",
       "      <td>Europe</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hall LLC</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Finance &amp; Banking</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Contract</td>\n",
       "      <td>117053.5</td>\n",
       "      <td>North Desireeland</td>\n",
       "      <td>Africa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ellis PLC</td>\n",
       "      <td>AI Product Manager</td>\n",
       "      <td>Retail &amp; E-commerce</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Remote</td>\n",
       "      <td>136675.0</td>\n",
       "      <td>South Kevin</td>\n",
       "      <td>Africa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Matthews-Moses</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Automotive &amp; Transportation</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>79584.5</td>\n",
       "      <td>West Shawn</td>\n",
       "      <td>Africa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Mullins Ltd</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Education</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Internship</td>\n",
       "      <td>72588.0</td>\n",
       "      <td>Port Hailey</td>\n",
       "      <td>Europe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Aguilar PLC</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Internship</td>\n",
       "      <td>161371.5</td>\n",
       "      <td>Butlermouth</td>\n",
       "      <td>Europe</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Parks LLC</td>\n",
       "      <td>Computer Vision Engineer</td>\n",
       "      <td>Automotive &amp; Transportation</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>122195.0</td>\n",
       "      <td>Nicoleshire</td>\n",
       "      <td>Europe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id              company_name              job_category  \\\n",
       "0       1           Foster and Sons              Data Analyst   \n",
       "1       2   Boyd, Myers and Ramirez  Computer Vision Engineer   \n",
       "2       3                  King Inc          Quant Researcher   \n",
       "3       4  Cooper, Archer and Lynch        AI Product Manager   \n",
       "4       5                  Hall LLC            Data Scientist   \n",
       "5       6                 Ellis PLC        AI Product Manager   \n",
       "6       7            Matthews-Moses              Data Analyst   \n",
       "7       8               Mullins Ltd            Data Scientist   \n",
       "8       9               Aguilar PLC               ML Engineer   \n",
       "9      10                 Parks LLC  Computer Vision Engineer   \n",
       "\n",
       "             industry_category experience_level_standardized  \\\n",
       "0                   Healthcare                           Mid   \n",
       "1                   Technology                        Senior   \n",
       "2                   Technology                         Entry   \n",
       "3                   Technology                           Mid   \n",
       "4            Finance & Banking                        Senior   \n",
       "5          Retail & E-commerce                        Senior   \n",
       "6  Automotive & Transportation                           Mid   \n",
       "7                    Education                         Entry   \n",
       "8                   Healthcare                         Entry   \n",
       "9  Automotive & Transportation                        Senior   \n",
       "\n",
       "  employment_type_standardized  salary_avg               city         region  \\\n",
       "0                    Full-Time    101229.0          Tracybury  South America   \n",
       "1                    Full-Time    111699.0         Lake Scott      Caribbean   \n",
       "2                    Full-Time    170850.0         East Paige         Africa   \n",
       "3                    Full-Time     87325.5          Perezview         Europe   \n",
       "4                     Contract    117053.5  North Desireeland         Africa   \n",
       "5                       Remote    136675.0        South Kevin         Africa   \n",
       "6                    Full-Time     79584.5         West Shawn         Africa   \n",
       "7                   Internship     72588.0        Port Hailey         Europe   \n",
       "8                   Internship    161371.5        Butlermouth         Europe   \n",
       "9                    Full-Time    122195.0        Nicoleshire         Europe   \n",
       "\n",
       "   num_skills_required  \n",
       "0                    6  \n",
       "1                    4  \n",
       "2                    6  \n",
       "3                    6  \n",
       "4                    4  \n",
       "5                    4  \n",
       "6                    4  \n",
       "7                    3  \n",
       "8                    4  \n",
       "9                    3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display key columns from cleaned data\n",
    "key_columns = [\n",
    "    'job_id', 'company_name', 'job_category', 'industry_category',\n",
    "    'experience_level_standardized', 'employment_type_standardized',\n",
    "    'salary_avg', 'city', 'region', 'num_skills_required'\n",
    "]\n",
    "\n",
    "print(\"Sample of Cleaned Data (Key Features):\")\n",
    "print(\"=\"*100)\n",
    "df_cleaned[key_columns].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055f522",
   "metadata": {},
   "source": [
    "## 15. Export Cleaned Data\n",
    "\n",
    "Save the cleaned dataset to a new CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f10f88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaned data exported successfully to: ../dataset/ai_job_market_cleaned.csv\n",
      "✓ Total records: 2000\n",
      "✓ Total columns: 36\n",
      "\n",
      "Cleaned dataset columns:\n",
      "['job_id', 'company_name', 'industry', 'job_title', 'skills_required', 'experience_level', 'employment_type', 'location', 'salary_range_usd', 'posted_date', 'company_size', 'tools_preferred', 'job_title_standardized', 'job_category', 'skills_list', 'tools_list', 'num_skills_required', 'num_tools_preferred', 'salary_min', 'salary_max', 'salary_avg', 'salary_category', 'city', 'country_code', 'country', 'region', 'industry_standardized', 'industry_category', 'experience_level_standardized', 'employment_type_standardized', 'company_size_standardized', 'posted_date_parsed', 'posted_year', 'posted_month', 'posted_quarter', 'posted_month_name']\n"
     ]
    }
   ],
   "source": [
    "# Export cleaned data to CSV\n",
    "output_path = '../dataset/ai_job_market_cleaned.csv'\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Cleaned data exported successfully to: {output_path}\")\n",
    "print(f\"✓ Total records: {len(df_cleaned)}\")\n",
    "print(f\"✓ Total columns: {len(df_cleaned.columns)}\")\n",
    "print(f\"\\nCleaned dataset columns:\")\n",
    "print(df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f703a8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Data Cleaning Operations Performed:\n",
    "\n",
    "1. **Missing Value Handling**\n",
    "   - Filled text columns with 'Unknown'\n",
    "   - Filled categorical columns with mode values\n",
    "   - Dropped rows with missing salary information\n",
    "\n",
    "2. **Text Standardization**\n",
    "   - Standardized job titles and created job categories\n",
    "   - Standardized and categorized industries\n",
    "   - Standardized experience levels and employment types\n",
    "   - Standardized company sizes\n",
    "\n",
    "3. **Skills Processing**\n",
    "   - Extracted and standardized skills from comma-separated lists\n",
    "   - Created skill count features\n",
    "   - Applied consistent naming conventions\n",
    "\n",
    "4. **Salary Processing**\n",
    "   - Parsed salary ranges into min, max, and average values\n",
    "   - Created salary categories for grouping\n",
    "   - Enabled numerical analysis of compensation\n",
    "\n",
    "5. **Location Processing**\n",
    "   - Parsed locations into city and country code\n",
    "   - Mapped country codes to full country names\n",
    "   - Mapped country codes to geographic regions\n",
    "   - Created hierarchical location structure (City → Country Code → Country Name → Region)\n",
    "\n",
    "6. **Date Processing**\n",
    "   - Converted dates to datetime format\n",
    "   - Extracted time-based features (year, month, quarter)\n",
    "\n",
    "### Key Features Created:\n",
    "\n",
    "- `job_category`: Categorized job titles\n",
    "- `industry_category`: Broader industry groupings\n",
    "- `salary_avg`: Average salary for analysis\n",
    "- `country`: Full country names from country codes\n",
    "- `region`: Geographic regions for location analysis\n",
    "- `num_skills_required`: Count of required skills\n",
    "- `posted_year`, `posted_month`, `posted_quarter`: Time-based features\n",
    "\n",
    "### Data Ready For:\n",
    "\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Statistical Analysis\n",
    "- Machine Learning Models\n",
    "- Visualization and Reporting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
