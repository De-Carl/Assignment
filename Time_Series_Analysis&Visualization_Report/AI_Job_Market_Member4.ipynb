{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d9df5d-f0f8-4ecd-89a3-181fd0cf6c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  posted_date  job_postings_count\n",
      "0      2023Q3                  30\n",
      "1      2023Q4                 241\n",
      "2      2024Q1                5847\n",
      "3      2024Q2                5872\n",
      "4      2024Q3                5954\n",
      "5      2024Q4                6033\n",
      "6      2025Q1                5730\n",
      "7      2025Q2                2071\n",
      "8      2025Q3                 222\n",
      "Saved: Member4_figure/quarterly_job_postings_trend.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"Member4_figure\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# File path to the cleaned CSV dataset\n",
    "file_path = \"ai_job_market_unified.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'posted_date' column to datetime format\n",
    "# errors='coerce' will replace invalid parsing with NaT (missing value)\n",
    "data['posted_date'] = pd.to_datetime(data['posted_date'], errors='coerce')\n",
    "\n",
    "# Group the data by quarter (Q) based on 'posted_date'\n",
    "# Count the number of job postings in each quarter\n",
    "quarterly_counts = (\n",
    "    data.groupby(data['posted_date'].dt.to_period('Q'))\n",
    "    .size()\n",
    "    .reset_index(name='job_postings_count')\n",
    ")\n",
    "\n",
    "# Convert the 'posted_date' period type back to string for plotting\n",
    "quarterly_counts['posted_date'] = quarterly_counts['posted_date'].astype(str)\n",
    "\n",
    "# Print the quarterly job posting counts\n",
    "print(quarterly_counts)\n",
    "\n",
    "# Plot the trend of job postings per quarter\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    quarterly_counts['posted_date'], \n",
    "    quarterly_counts['job_postings_count'], \n",
    "    marker='o', linestyle='-'\n",
    ")\n",
    "plt.title(\"Quarterly Job Postings Trend\", fontsize=14)  # Title of the chart\n",
    "plt.xlabel(\"Quarter\")  # X-axis label\n",
    "plt.ylabel(\"Number of Job Postings\")  # Y-axis label\n",
    "plt.grid(True)  # Add grid lines for better readability\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better display\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.savefig(os.path.join(output_dir, \"quarterly_job_postings_trend.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {os.path.join(output_dir, 'quarterly_job_postings_trend.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d830f54b-9b4f-40e5-ab3c-cc09e80b379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Job Title Trend]\n",
      "job_title  AI Architect  AI Product Manager  Autonomous Systems Engineer  \\\n",
      "period                                                                     \n",
      "2023Q3                0                   6                            0   \n",
      "2023Q4                0                  30                            0   \n",
      "2024Q1              289                 349                          287   \n",
      "2024Q2              283                 293                          291   \n",
      "2024Q3              282                 329                          252   \n",
      "2024Q4              306                 320                          310   \n",
      "2025Q1              283                 298                          292   \n",
      "2025Q2               86                 110                          100   \n",
      "2025Q3                0                  30                            0   \n",
      "\n",
      "job_title  Computer Vision Engineer  Data Analyst  Data Scientist  \\\n",
      "period                                                              \n",
      "2023Q3                            4             2               6   \n",
      "2023Q4                           34            28              29   \n",
      "2024Q1                          320           306            1135   \n",
      "2024Q2                          309           323            1161   \n",
      "2024Q3                          333           324            1140   \n",
      "2024Q4                          304           317            1213   \n",
      "2025Q1                          274           300            1108   \n",
      "2025Q2                          133           135             399   \n",
      "2025Q3                           23            29              25   \n",
      "\n",
      "job_title  ML Engineer  NLP Engineer  \n",
      "period                                \n",
      "2023Q3               0             1  \n",
      "2023Q4              28            35  \n",
      "2024Q1             592           318  \n",
      "2024Q2             648           325  \n",
      "2024Q3             652           325  \n",
      "2024Q4             585           318  \n",
      "2025Q1             607           296  \n",
      "2025Q2             209           120  \n",
      "2025Q3              29            30  \n",
      "Exported: job_title_trend_Q.csv\n",
      "Saved: Member4_figure/job_title_demand_trend.png\n",
      "\n",
      "[Skill Trend]\n",
      "skill   GCP  Kubernetes  Linux  PyTorch  Python   SQL  Scala  TensorFlow\n",
      "period                                                                  \n",
      "2023Q3   10           0      0        9       7     5      0          10\n",
      "2023Q4   45           0      0       41      51    49      0          56\n",
      "2024Q1  969        1092    979     1065    1688  1354   1014        1241\n",
      "2024Q2  988        1090   1052     1085    1749  1330   1080        1181\n",
      "2024Q3  991        1185   1025     1136    1724  1381   1043        1190\n",
      "2024Q4  986        1202   1004     1185    1809  1385   1074        1247\n",
      "2025Q1  944        1142    964     1068    1690  1305    977        1173\n",
      "2025Q2  328         376    323      373     580   467    354         428\n",
      "2025Q3   45           0      0       47      53    50      0          44\n",
      "Exported: skill_trend_Q.csv\n",
      "Saved: Member4_figure/skill_demand_trend.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ========== CONFIGURATION PARAMETERS ==========\n",
    "FILE_PATH = \"ai_job_market_unified.csv\"  # Path to the cleaned CSV dataset\n",
    "FREQ = \"Q\"                                 # Frequency for aggregation: \"Q\" = Quarterly, \"M\" = Monthly\n",
    "TOP_K_IF_EMPTY = 8                         # Number of top job titles/skills to select if none are specified\n",
    "EXPORT_CSV = True                          # Whether to export results to CSV files\n",
    "OUTPUT_DIR = \"Member4_figure\"   # Directory to save figures\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# List of target job titles to track; if empty, top N titles will be selected\n",
    "TARGET_JOB_TITLES = [\n",
    "  \n",
    "]\n",
    "\n",
    "# List of target skills to track; if empty, top N skills will be selected\n",
    "TARGET_SKILLS = [\n",
    "\n",
    "]\n",
    "\n",
    "# ========== FUNCTIONS ==========\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the CSV data into a pandas DataFrame.\n",
    "    Convert 'posted_date' to datetime format and drop rows with missing dates.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"posted_date\"] = pd.to_datetime(df[\"posted_date\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"posted_date\"])\n",
    "    return df\n",
    "\n",
    "def to_period_label(s: pd.Series, freq: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert datetime series into period labels based on frequency.\n",
    "    freq = \"Q\" -> Quarterly\n",
    "    freq = \"M\" -> Monthly\n",
    "    \"\"\"\n",
    "    if freq.upper() == \"Q\":\n",
    "        return s.dt.to_period(\"Q\").astype(str)\n",
    "    elif freq.upper() == \"M\":\n",
    "        return s.dt.to_period(\"M\").astype(str)\n",
    "    else:\n",
    "        raise ValueError(\"FREQ must be 'M' or 'Q'\")\n",
    "\n",
    "def aggregate_job_title_trend(df: pd.DataFrame, titles: list | None, freq: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate job posting counts over time for specified job titles.\n",
    "    If titles are not provided, use the top N most frequent job titles.\n",
    "    Returns a pivot table with periods as rows and job titles as columns.\n",
    "    \"\"\"\n",
    "    if not titles:\n",
    "        top_titles = df[\"job_title\"].value_counts().head(TOP_K_IF_EMPTY).index.tolist()\n",
    "    else:\n",
    "        top_titles = titles\n",
    "\n",
    "    use = df[df[\"job_title\"].isin(top_titles)].copy()\n",
    "    use[\"period\"] = to_period_label(use[\"posted_date\"], freq)\n",
    "    grouped = (\n",
    "        use.groupby([\"period\", \"job_title\"])\n",
    "           .size()\n",
    "           .reset_index(name=\"count\")\n",
    "           .sort_values([\"period\", \"job_title\"])\n",
    "    )\n",
    "    pivot = grouped.pivot(index=\"period\", columns=\"job_title\", values=\"count\").fillna(0).astype(int)\n",
    "    pivot = pivot.sort_index()  \n",
    "    return pivot\n",
    "\n",
    "def explode_skills_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Split the 'skills_required' column (comma-separated skills) into individual rows.\n",
    "    Returns a DataFrame with one skill per row.\n",
    "    \"\"\"\n",
    "    skills = (\n",
    "        df.dropna(subset=[\"skills_required\"])\n",
    "          .assign(skill=lambda x: x[\"skills_required\"].str.split(\",\"))\n",
    "          .explode(\"skill\")\n",
    "    )\n",
    "    skills[\"skill\"] = skills[\"skill\"].str.strip()\n",
    "    skills = skills[skills[\"skill\"] != \"\"]\n",
    "    return skills\n",
    "\n",
    "def aggregate_skill_trend(df: pd.DataFrame, skills: list | None, freq: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate job posting counts over time for specified skills.\n",
    "    If skills are not provided, use the top N most frequent skills.\n",
    "    Returns a pivot table with periods as rows and skills as columns.\n",
    "    \"\"\"\n",
    "    skill_df = explode_skills_column(df)\n",
    "    if not skills:\n",
    "        top_skills = skill_df[\"skill\"].value_counts().head(TOP_K_IF_EMPTY).index.tolist()\n",
    "    else:\n",
    "        top_skills = skills\n",
    "\n",
    "    use = skill_df[skill_df[\"skill\"].isin(top_skills)].copy()\n",
    "    use[\"period\"] = to_period_label(use[\"posted_date\"], freq)\n",
    "    grouped = (\n",
    "        use.groupby([\"period\", \"skill\"])\n",
    "           .size()\n",
    "           .reset_index(name=\"count\")\n",
    "           .sort_values([\"period\", \"skill\"])\n",
    "    )\n",
    "    pivot = grouped.pivot(index=\"period\", columns=\"skill\", values=\"count\").fillna(0).astype(int)\n",
    "    pivot = pivot.sort_index()\n",
    "    return pivot\n",
    "\n",
    "def plot_lines(pivot: pd.DataFrame, title: str, filename: str, xlabel: str = \"Period\", ylabel: str = \"Job Postings\"):\n",
    "    \"\"\"\n",
    "    Plot line charts for job title or skill trends.\n",
    "    Each column in the pivot table is plotted as a separate line.\n",
    "    Save the figure to the output directory.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    for col in pivot.columns:\n",
    "        plt.plot(pivot.index, pivot[col], marker=\"o\", label=str(col))\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(OUTPUT_DIR, filename)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved: {save_path}\")\n",
    "\n",
    "def maybe_export_csv(df: pd.DataFrame, name: str, freq: str):\n",
    "    \"\"\"\n",
    "    Export the pivot table DataFrame to a CSV file if EXPORT_CSV is True.\n",
    "    The filename includes the type of trend and frequency (M/Q).\n",
    "    \"\"\"\n",
    "    if not EXPORT_CSV:\n",
    "        return\n",
    "    out = Path(f\"{name}_{freq}.csv\")\n",
    "    df.to_csv(out, encoding=\"utf-8-sig\")\n",
    "    print(f\"Exported: {out}\")\n",
    "\n",
    "\n",
    "# ========== MAIN SCRIPT EXECUTION ==========\n",
    "\n",
    "# Load dataset\n",
    "data = load_data(FILE_PATH)\n",
    "\n",
    "# ---- Job Title Trend ----\n",
    "job_pivot = aggregate_job_title_trend(data, TARGET_JOB_TITLES, FREQ)\n",
    "print(\"\\n[Job Title Trend]\")\n",
    "print(job_pivot)\n",
    "maybe_export_csv(job_pivot, \"job_title_trend\", FREQ)\n",
    "plot_lines(job_pivot, title=f\"Job Title Demand Trend ({FREQ})\", filename=\"job_title_demand_trend.png\")\n",
    "\n",
    "# ---- Skill Trend ----\n",
    "skill_pivot = aggregate_skill_trend(data, TARGET_SKILLS, FREQ)\n",
    "print(\"\\n[Skill Trend]\")\n",
    "print(skill_pivot)\n",
    "maybe_export_csv(skill_pivot, \"skill_trend\", FREQ)\n",
    "plot_lines(skill_pivot, title=f\"Skill Demand Trend ({FREQ})\", filename=\"skill_demand_trend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a7c18e-df6b-4f40-bf51-3a78fac9457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Member4_figure/salary_heatmap_by_region_industry.png\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# File path to the cleaned CSV dataset\n",
    "file_path = \"ai_job_market_unified.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a pivot table for heatmap:\n",
    "# - Rows: regions\n",
    "# - Columns: industry categories\n",
    "# - Values: average salary (salary_avg)\n",
    "# - Fill missing values with 0\n",
    "heatmap_data = pd.pivot_table(\n",
    "    data,\n",
    "    index='region',\n",
    "    columns='industry_category',\n",
    "    values='salary_avg',\n",
    "    aggfunc='mean',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Plot heatmap of average salary by region and industry category\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"RdYlGn\",                   # Color palette (Red-Yellow-Green for salary levels)\n",
    "    annot=True,                     # Annotate cells with values\n",
    "    fmt=\".0f\",                      # Format as integer\n",
    "    cbar_kws={'label': 'Average Salary (USD)'}  # Color bar label\n",
    ")\n",
    "plt.title(\"Heatmap of Average Salary by Region and Industry Category\", fontsize=16)  # Chart title\n",
    "plt.xlabel(\"Industry Category\")   # X-axis label\n",
    "plt.ylabel(\"Region\")    # Y-axis label\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.savefig(os.path.join(output_dir, \"salary_heatmap_by_region_industry.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {os.path.join(output_dir, 'salary_heatmap_by_region_industry.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2713ac-a76e-4374-8ce2-3ffc413f972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Member4_figure/top_10_skills_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to the cleaned CSV dataset\n",
    "file_path = \"ai_job_market_unified.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the 'skills_required' column, drop missing values, \n",
    "# split comma-separated skills into lists, explode into separate rows,\n",
    "# and remove extra whitespace\n",
    "skills = data['skills_required'].dropna().str.split(',').explode().str.strip()\n",
    "\n",
    "# Count the frequency of each skill and select the top 10 most common\n",
    "skill_counts = skills.value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 skills as a bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "skill_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.title(\"Top 10 Skills Distribution\", fontsize=14)  # Chart title\n",
    "plt.ylabel(\"Count\")  # Y-axis label\n",
    "plt.xlabel(\"Skills\")  # X-axis label\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()  # Adjust layout to avoid overlap\n",
    "plt.savefig(os.path.join(output_dir, \"top_10_skills_distribution.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {os.path.join(output_dir, 'top_10_skills_distribution.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ada9c8a6-93ab-4635-a765-782580998782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Member4_figure/top_10_tools_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to the cleaned CSV dataset\n",
    "file_path = \"ai_job_market_unified.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the 'tools_preferred' column, drop missing values,\n",
    "# split comma-separated tool names into lists, \n",
    "# expand lists into separate rows (explode), and strip extra whitespace\n",
    "salary_category = data['salary_category'].dropna().str.split(',').explode().str.strip()\n",
    "\n",
    "# Count the frequency of each tool and select the top 10 most common\n",
    "tool_counts = salary_category.value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 tools as a bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "tool_counts.plot(kind=\"bar\", color=\"lightgreen\")\n",
    "plt.title(\"Top 10 Tools Distribution\", fontsize=14)  # Chart title\n",
    "plt.ylabel(\"Count\")  # Y-axis label\n",
    "plt.xlabel(\"Tools\")  # X-axis label\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()  # Adjust layout to avoid overlap\n",
    "plt.savefig(os.path.join(output_dir, \"top_10_tools_distribution.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {os.path.join(output_dir, 'top_10_tools_distribution.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd9c07e-f6e0-4139-ad89-0cf779c7dd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Member4_figure/industry_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to the cleaned CSV dataset\n",
    "file_path = \"ai_job_market_unified.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Count the frequency of values in the 'industry' column\n",
    "# Select the top 8 industries with the highest counts\n",
    "industry_counts = data['industry_standardized'].value_counts().head(8)\n",
    "\n",
    "# Plot the top 8 industries as a pie chart\n",
    "plt.figure(figsize=(8,8))\n",
    "industry_counts.plot(\n",
    "    kind=\"pie\",                      # Pie chart\n",
    "    autopct=\"%1.1f%%\",               # Show percentages with 1 decimal place\n",
    "    startangle=140,                  # Rotate start angle for better visualization\n",
    "    colors=plt.cm.Paired.colors      # Use a paired color palette\n",
    ")\n",
    "plt.title(\"Industry Distribution\", fontsize=14)  # Chart title\n",
    "plt.ylabel(\"\")  # Remove y-axis label for a cleaner look\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.savefig(os.path.join(output_dir, \"industry_distribution.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {os.path.join(output_dir, 'industry_distribution.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca7acd3-922d-45c6-9ff2-c092850f9d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Member4_figure/top_10_companies_hiring.png\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to the cleaned CSV dataset\n",
    "file_path = \"ai_job_market_unified.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Count the number of job postings per company\n",
    "# Select the top 10 companies with the most postings\n",
    "company_counts = data['company_name'].value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 companies as a bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "company_counts.plot(kind=\"bar\", color=\"orange\")\n",
    "plt.title(\"Top 10 Companies Hiring\", fontsize=14)  # Chart title\n",
    "plt.ylabel(\"Job Postings\")  # Y-axis label\n",
    "plt.xlabel(\"Company\")       # X-axis label\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "plt.savefig(os.path.join(output_dir, \"top_10_companies_hiring.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {os.path.join(output_dir, 'top_10_companies_hiring.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d16df-ce23-4e37-971b-8599d15a69f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
